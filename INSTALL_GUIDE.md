# üéØ H∆Ø·ªöNG D·∫™N C√ÄI ƒê·∫∂T CUDA WHISPER - PHI√äN B·∫¢N STABLE

## ‚ö° C√†i ƒë·∫∑t nhanh (khuy·∫øn ngh·ªã)

```bash
# Clone project (n·∫øu ch∆∞a c√≥)
cd /media/hao/Work/Documents/Apps/VoiceSub-Translator

# Ch·∫°y script t·ª± ƒë·ªông
chmod +x install_stable.sh
./install_stable.sh
```

## üìã C√†i ƒë·∫∑t th·ªß c√¥ng t·ª´ng b∆∞·ªõc

### B∆∞·ªõc 1: T·∫°o m√¥i tr∆∞·ªùng ·∫£o
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
```

### B∆∞·ªõc 2: Core Dependencies
```bash
pip install numpy==1.26.4 filelock==3.18.0 typing-extensions==4.13.2 fsspec==2025.5.1
```

### B∆∞·ªõc 3: PyTorch v·ªõi CUDA (QUAN TR·ªåNG: c√†i tr∆∞·ªõc Triton)
```bash
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118
```

### B∆∞·ªõc 4: Triton (sau PyTorch)
```bash
pip install triton==2.1.0
```

### B∆∞·ªõc 5: Whisper Models
```bash
pip install openai-whisper==20231117 faster-whisper==1.1.1
```

### B∆∞·ªõc 6: C√°c th∆∞ vi·ªán c√≤n l·∫°i
```bash
pip install -r requirements_stable.txt
```

## üß™ Ki·ªÉm tra c√†i ƒë·∫∑t

### Test CUDA
```bash
python3 -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

### Test Whisper
```bash
python3 -c "import whisper; model = whisper.load_model('base.en', device='cuda'); print('Whisper OK')"
```

### Test ·ª©ng d·ª•ng
```bash
python3 src/gui/app.py
```

## üîß Versions ƒë√£ test th√†nh c√¥ng

| Package | Version | Link |
|---------|---------|------|
| PyTorch | 2.1.0+cu118 | https://download.pytorch.org/whl/cu118 |
| Triton | 2.1.0 | PyPI |
| NumPy | 1.26.4 | PyPI |
| OpenAI Whisper | 20231117 | PyPI |
| Faster Whisper | 1.1.1 | PyPI |

## ‚ùå X·ª≠ l√Ω l·ªói th∆∞·ªùng g·∫∑p

### L·ªói Triton version conflict
```bash
pip uninstall triton
pip install triton==2.1.0
```

### L·ªói NumPy compatibility
```bash
pip install "numpy<2.0"
```

### L·ªói CUDA not found
- Ki·ªÉm tra NVIDIA driver: `nvidia-smi`
- Reinstall PyTorch v·ªõi CUDA: xem B∆∞·ªõc 3

### Reset ho√†n to√†n
```bash
rm -rf .venv
./install_stable.sh
```

## üéØ C√°ch s·ª≠ d·ª•ng

### GUI Application
```bash
source .venv/bin/activate
python3 src/gui/app.py
```

### Command Line
```bash
source .venv/bin/activate
python3 src/utils/whisper_transcriber.py input.mp4 --model base.en --device cuda
```

## üìä Y√™u c·∫ßu h·ªá th·ªëng

- Ubuntu 18.04+ ho·∫∑c Linux t∆∞∆°ng t·ª±
- Python 3.8+
- NVIDIA GPU v·ªõi CUDA 11.8+
- RAM: 8GB+ (khuy·∫øn ngh·ªã 16GB)
- Disk: 5GB+ free space

## üîç Debug

### Ki·ªÉm tra GPU
```bash
nvidia-smi
python3 -c "import torch; print(torch.cuda.get_device_name(0))"
```

### Ki·ªÉm tra versions
```bash
pip list | grep -E "(torch|triton|whisper|numpy)"
```

### Log debug
```bash
export LOG_LEVEL=DEBUG
python3 src/gui/app.py
```

---
**L∆∞u √Ω:** File n√†y ƒë√£ ƒë∆∞·ª£c test tr√™n h·ªá th·ªëng Ubuntu v·ªõi GTX 1650 Ti. N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, h√£y ch·∫°y l·∫°i script `install_stable.sh`.
